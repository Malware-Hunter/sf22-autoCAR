
coisas novas: 
- permitir ao usuário executar: ./main.py (incluir #!/usr/bin/python3, ou algo assim, no cabeçalho do arquivo)
- inverter as instruções no README.md (primeiro instalar o r-base, para depois instalar os requirements)
- criar um Dockerfile para geração da imagem Linux completa
- atualizar o README.md e indicar também o script setup.sh (que já faz tudo direitinho)
- falta o pyarc nos requirements

- se eu digito: python3 main.py --datasets datasets/androit.csv
saida (não executa e nem ajuda o usuário):
Namespace(list_models=None, list_models_all=False, datasets=['datasets/androit.csv'], use_balanced_datasets=False, verbose=False, run_cbar=None, run_cbar_all=False, run_ml=None, run_ml_all=False, plot_graph=None, output_dir='outputs')

- se eu digito: python3 main.py --datasets datasets/androit.csv --run-cbar-all --run-ml-all --output-dir teste 
nada acontece. imprime a ajuda. não era para executar com esses parâmetros?



**testes no Debian10 e Ubuntu22.04**

** antes dos requirements, falta:
sudo apt install r-base

** na hora de executar, falta:
sudo python3 -m pip install termcolor


** na hora de usar:
** parâmetro --list-models ficou confuso. quais são os MODEL_TYPE disponíveis? como o usuário vai saber o nome desses tipos?

python3 main.py --list-models
usage: main.py [-h] [--list-models MODEL_TYPE [MODEL_TYPE ...] |
               --list-models-all]
main.py: error: argument --list-models: expected at least one argument

>> Agora toda vez que ocorre um erro no argparse é mostrado o help

** escolhendo um parâmetro errado, acabei descobrindo. mas, isto não será nada intuitivo para o usuário:

python3 main.py --list-models CBA
usage: main.py [-h] [--list-models MODEL_TYPE [MODEL_TYPE ...] |
               --list-models-all]
main.py: error: argument --list-models: invalid choice: 'CBA' (choose from 'cbar', 'ml')

python3 main.py --list-models cbar
Namespace(list_models=['cbar'], list_models_all=False)

>>> Classification Models Based on Association Rules
	CBA: Classification Based on Association Rules
	EQAR: ECLAT and Qualify Association Rules
	CPAR: Classification based on Predictive Association Rules
	CMAR: Classification based on Multiple Class-Association Rules

** por que a maioria dos parâmetros é "--" e o dataset é "-d"? por que não "--dataset" ou "--datasets"?

>> Pode ser tanto -d como --datasets. Posso tirar o -d se for o caso.

** por que quando mostra os métodos os nomes são RF e SVM e quando vai usar tem que ser "rf" e "svm"? não faz muito sentido e confunde o usuário. não dá pra permitir RF e rf? pega o parâmetro que o usuário digita e transforma em lower case.
python3 main.py --use-balanced-datasets --run-cbar-all --run-ml RF
usage: main.py [-h] [--list-models MODEL_TYPE [MODEL_TYPE ...] |
               --list-models-all] -d DATASET [DATASET ...]
               [--use-balanced-datasets] [--verbose]
               [--run-cbar CBAR [CBAR ...] | --run-cbar-all]
               [--run-ml ML [ML ...] | --run-ml-all] [--plot-graph-all]
               [-s float] [-c float] [-m int] [-a AR_ALGORITHM] [-l float]
               [-t float] -q QUALIFY [-o] [--prefix-output-cbar-cba PREFIX]
               [--prefix-output-cbar-eqar PREFIX]
               [--prefix-output-cbar-cpar PREFIX]
               [--prefix-output-cbar-cmar PREFIX] [--output-dir DIRECTORY]
main.py: error: argument --run-ml: invalid choice: 'RF' (choose from 'svm', 'rf')

>> Feito

** seria bom ter alguns datasets pequenos no repositório para testes rápidas. pode ser versões reduzidas do Drebin e Androcrawl, por exemplo. poucas centenas de amostras é o suficiente para testes rápidas.
